{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fd746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\anaconda\\envs\\llm\\lib\\site-packages\\transformers\\utils\\hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer,AutoConfig,AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c0ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"../../model/gpt2\"\n",
    "CLLM = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer= AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "llm = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3fdc1f",
   "metadata": {},
   "source": [
    "### CLLM 跟 LLM的区别\n",
    "- 多了一个MLPHead,维度为(outputsize,vocal_size)\n",
    "\n",
    "### gpt2属于自回归模型\n",
    "- 对于输入x,得到$y_1$,然后将[x,$y_1$]作为输入,接着得到$y_2$\n",
    "### greed_search vs. beam_search\n",
    "- greed_search:贪心策略，对于每次的输入y,总是选择概率最大的那个,弊端：输出缺乏多样性,场景：数学(要求精确，而不是多样)\n",
    "- beam_search:束搜索，输入的时候进行束(k)展开，每次输出都进行k展开，最后计算得到最大概率的输出\n",
    "\n",
    "### 对logits\n",
    "- 对任意句子(i have a )，进行tokenizer编码后(假设不包含special_token)，得到input_ids,长度为tokens_len\n",
    "- 将input_ids输入到model中,即output = model(input_ids=input_ids),\n",
    "- 得到output.logits,维度为(batch_size,tokens_len,vocab_size)\n",
    "- 对于非最后一个token,即(batch_size,tokens_len[i],vocab_size),i!=-1,输出的含义:model更加偏向对该位置token的预测,\n",
    "    - 例如(batch_size,tokens_len[0],vocab_size),是指model对第一个token(i)的预测概率的一个排序\n",
    "- 而对于最后一个token,即(batch_size,tokens_len[-1],vocab_size),输出的含义:model更加偏向对下一个token的预测\n",
    "    - 例如(batch_size,tokens_len[-1],vocab_size),更多的是对apple这个token的预测，而不是a这个token的预测\n",
    "\n",
    "### 函数\n",
    "- torch.argsort(),返回张量排序后的索引（indices）\n",
    "    - 例如：lst = [3.1,-0.8,2.5],torch.argsort(lst),得到[1,2,0](升序顺序)\n",
    "    - torch.argsort(lst,descending=True),得到[0,2,1](降序顺序)\n",
    "- torch.argmax(),返回张量顺序后最大的索引\n",
    "    - torch.argmax(lst),得到[0]\n",
    "- model.generate()\n",
    "    - max_length:prompt+generation的长度\n",
    "    - max_new_tokens:generation的长度\n",
    "    - 默认greed_search,如果beam_num不设置的话\n",
    "  \n",
    "### 如何理解tokenizer.decode()的时候，是tokenizer.decode(torch.argmax(lst)),是decode的索引,而不是logits\n",
    "- 对于model(input_ids = input_ids).logits[:,-1,:],得到的是模型对于vocab再该位置输出token的概率\n",
    "- 其中logits[:,-1,:]潜在的包含了顺序的关系，可以理解为logits[:,-1,:][0],表示的是对于词汇表token ids为0对应的token的概率\n",
    "- 然后经过torch.argmax(lst)得到最大概率的索引,假设为100,那么logits[:,-1,:][100],是最大的概率对应的logits,那么根据上面可以得到logits[:,-1,:][100]表示的是对于词汇表第token ids为1000对应的token的概率\n",
    "- 然后经过tokenizer.decode(torch.argmax(lst)),即tokenizer.decode([100]),就是相应的token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff64aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Hello, how are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2164ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-118.5744, -117.4402, -120.4907,  ..., -128.7235, -129.1531,\n",
      "         -116.4908]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[1.7369e-01, 9.4105e-02, 3.2945e-02,  ..., 2.5862e-14, 2.3738e-14,\n",
      "         4.7234e-15]]),\n",
      "indices=tensor([[  198,   314,  1867,  ..., 19476, 33434, 13945]]))\n",
      "tensor([[  198,   314,  1867,  ..., 19476, 33434, 13945]])\n",
      "17.369191348552704\n",
      "9.410453587770462\n",
      "3.2944701611995697\n",
      "3.2210029661655426\n",
      "3.165554627776146\n",
      "第0次 {'percentage位置0': '\\n的概率17.3692%', 'percentage位置1': ' I的概率9.4105%', 'percentage位置2': ' What的概率3.2945%', 'percentage位置3': ' How的概率3.2210%', 'percentage位置4': ' You的概率3.1656%', 'sentence第0次': 'Hello, how are you?'}\n",
      "tensor([[-183.2317, -177.2168, -180.8680,  ..., -198.4083, -204.2615,\n",
      "         -179.7054]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[9.9432e-01, 5.6672e-04, 2.9005e-04,  ..., 1.4587e-25, 7.8114e-26,\n",
      "         6.4557e-26]]),\n",
      "indices=tensor([[  198,    40,    32,  ...,  7782, 14695, 27013]]))\n",
      "tensor([[  198,    40,    32,  ...,  7782, 14695, 27013]])\n",
      "99.43156838417053\n",
      "0.05667225341312587\n",
      "0.029005485703237355\n",
      "0.02543994050938636\n",
      "0.009946626960299909\n",
      "第1次 {'percentage位置0': '\\n的概率99.4316%', 'percentage位置1': 'I的概率0.0567%', 'percentage位置2': 'A的概率0.0290%', 'percentage位置3': 'The的概率0.0254%', 'percentage位置4': 'M的概率0.0099%', 'sentence第1次': 'Hello, how are you?\\n'}\n",
      "tensor([[-101.5588,  -94.8756,  -99.0220,  ..., -114.8675, -115.8206,\n",
      "         -105.3101]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[7.2990e-02, 3.1469e-02, 2.3875e-02,  ..., 5.2794e-18, 5.0250e-18,\n",
      "         1.3875e-18]]),\n",
      "indices=tensor([[   40,     1,  1639,  ..., 13150, 15272, 14695]]))\n",
      "tensor([[   40,     1,  1639,  ..., 13150, 15272, 14695]])\n",
      "7.298985868692398\n",
      "3.146880120038986\n",
      "2.3874539881944656\n",
      "1.9681857898831367\n",
      "1.920071616768837\n",
      "第2次 {'percentage位置0': 'I的概率7.2990%', 'percentage位置1': '\"的概率3.1469%', 'percentage位置2': 'You的概率2.3875%', 'percentage位置3': 'The的概率1.9682%', 'percentage位置4': 'A的概率1.9201%', 'sentence第2次': 'Hello, how are you?\\n\\n'}\n",
      "tensor([[-139.0177, -139.4389, -143.4381,  ..., -150.7664, -141.7181,\n",
      "         -142.2784]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[4.1710e-01, 1.2605e-01, 5.5294e-02,  ..., 2.6966e-16, 1.3873e-16,\n",
      "         1.0256e-16]]),\n",
      "indices=tensor([[ 1101,   716,  1053,  ...,   174,  4204, 17629]]))\n",
      "tensor([[ 1101,   716,  1053,  ...,   174,  4204, 17629]])\n",
      "41.710224747657776\n",
      "12.604966759681702\n",
      "5.529352277517319\n",
      "4.2741212993860245\n",
      "2.700512669980526\n",
      "第3次 {'percentage位置0': \"'m的概率41.7102%\", 'percentage位置1': ' am的概率12.6050%', 'percentage位置2': \"'ve的概率5.5294%\", 'percentage位置3': ' was的概率4.2741%', 'percentage位置4': ' have的概率2.7005%', 'sentence第3次': 'Hello, how are you?\\n\\nI'}\n",
      "tensor([[-121.6031, -123.1548, -126.1836,  ..., -130.9444, -129.3738,\n",
      "         -124.9072]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[5.9283e-02, 4.2078e-02, 4.1196e-02,  ..., 2.7315e-15, 2.7211e-15,\n",
      "         2.0168e-15]]),\n",
      "indices=tensor([[  257,   407,   655,  ...,   191,   179, 18945]]))\n",
      "tensor([[  257,   407,   655,  ...,   191,   179, 18945]])\n",
      "5.928270518779755\n",
      "4.207783937454224\n",
      "4.119635373353958\n",
      "3.708232194185257\n",
      "2.826654352247715\n",
      "第4次 {'percentage位置0': ' a的概率5.9283%', 'percentage位置1': ' not的概率4.2078%', 'percentage位置2': ' just的概率4.1196%', 'percentage位置3': ' fine的概率3.7082%', 'percentage位置4': ' so的概率2.8267%', 'sentence第4次': \"Hello, how are you?\\n\\nI'm\"}\n",
      "tensor([[-108.2009, -107.9839, -110.3405,  ..., -116.5634, -114.6584,\n",
      "         -109.0663]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[3.8726e-02, 1.9160e-02, 1.5891e-02,  ..., 4.1443e-13, 3.0414e-13,\n",
      "         2.2084e-13]]),\n",
      "indices=tensor([[ 1310,  1643,  1263,  ...,   180, 39756, 39803]]))\n",
      "tensor([[ 1310,  1643,  1263,  ...,   180, 39756, 39803]])\n",
      "3.8726262748241425\n",
      "1.9159777089953423\n",
      "1.5891043469309807\n",
      "1.3933997601270676\n",
      "1.2249048799276352\n",
      "第5次 {'percentage位置0': ' little的概率3.8726%', 'percentage位置1': ' bit的概率1.9160%', 'percentage位置2': ' big的概率1.5891%', 'percentage位置3': ' very的概率1.3934%', 'percentage位置4': ' young的概率1.2249%', 'sentence第5次': \"Hello, how are you?\\n\\nI'm a\"}\n",
      "tensor([[-107.9235, -107.0753, -112.7063,  ..., -115.7501, -113.5265,\n",
      "         -109.7522]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[1.3478e-01, 5.2475e-02, 4.4740e-02,  ..., 1.1760e-14, 1.0963e-14,\n",
      "         1.0365e-14]]),\n",
      "indices=tensor([[ 1643, 10927, 10032,  ..., 30898,   215,  4060]]))\n",
      "tensor([[ 1643, 10927, 10032,  ..., 30898,   215,  4060]])\n",
      "13.477693498134613\n",
      "5.2475061267614365\n",
      "4.474036023020744\n",
      "3.7622306495904922\n",
      "2.828053943812847\n",
      "第6次 {'percentage位置0': ' bit的概率13.4777%', 'percentage位置1': ' nervous的概率5.2475%', 'percentage位置2': ' tired的概率4.4740%', 'percentage位置3': ' confused的概率3.7622%', 'percentage位置4': ' surprised的概率2.8281%', 'sentence第6次': \"Hello, how are you?\\n\\nI'm a little\"}\n",
      "tensor([[-105.8923, -104.9962, -112.9595,  ..., -114.8803, -111.6777,\n",
      "         -109.5163]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[6.2405e-02, 4.8432e-02, 4.7552e-02,  ..., 4.5894e-15, 4.3230e-15,\n",
      "         3.7916e-15]]),\n",
      "indices=tensor([[  286, 10927,  4697,  ...,  4060, 18945, 31204]]))\n",
      "tensor([[  286, 10927,  4697,  ...,  4060, 18945, 31204]])\n",
      "6.240548193454742\n",
      "4.843190684914589\n",
      "4.755207523703575\n",
      "4.488592967391014\n",
      "3.040379472076893\n",
      "第7次 {'percentage位置0': ' of的概率6.2405%', 'percentage位置1': ' nervous的概率4.8432%', 'percentage位置2': ' older的概率4.7552%', 'percentage位置3': ' tired的概率4.4886%', 'percentage位置4': ' confused的概率3.0404%', 'sentence第7次': \"Hello, how are you?\\n\\nI'm a little bit\"}\n",
      "tensor([[-78.8161, -77.6324, -82.1101,  ..., -85.2831, -85.3717, -79.3820]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[8.1726e-01, 1.0630e-01, 1.7132e-02,  ..., 2.5497e-13, 2.3601e-13,\n",
      "         1.3747e-13]]),\n",
      "indices=tensor([[  257,   281,  1111,  ..., 13945, 20686,  4060]]))\n",
      "tensor([[  257,   281,  1111,  ..., 13945, 20686,  4060]])\n",
      "81.72585964202881\n",
      "10.63002273440361\n",
      "1.713242568075657\n",
      "0.5506519228219986\n",
      "0.4627023357897997\n",
      "第8次 {'percentage位置0': ' a的概率81.7259%', 'percentage位置1': ' an的概率10.6300%', 'percentage位置2': ' both的概率1.7132%', 'percentage位置3': ' everything的概率0.5507%', 'percentage位置4': ' the的概率0.4627%', 'sentence第8次': \"Hello, how are you?\\n\\nI'm a little bit of\"}\n",
      "tensor([[-113.1392, -111.2405, -115.9748,  ..., -119.1921, -117.2603,\n",
      "         -112.4979]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[2.2674e-02, 1.2833e-02, 1.1876e-02,  ..., 4.0085e-13, 3.9433e-13,\n",
      "         3.2010e-13]]),\n",
      "indices=tensor([[34712, 27314,  4336,  ..., 30898,   180, 39500]]))\n",
      "tensor([[34712, 27314,  4336,  ..., 30898,   180, 39500]])\n",
      "2.26737093180418\n",
      "1.2832937762141228\n",
      "1.1875682510435581\n",
      "1.041385903954506\n",
      "1.0347254574298859\n",
      "第9次 {'percentage位置0': ' nerd的概率2.2674%', 'percentage位置1': ' geek的概率1.2833%', 'percentage位置2': ' fan的概率1.1876%', 'percentage位置3': ' mystery的概率1.0414%', 'percentage位置4': ' mess的概率1.0347%', 'sentence第9次': \"Hello, how are you?\\n\\nI'm a little bit of a\"}\n"
     ]
    }
   ],
   "source": [
    "CLLM.eval()\n",
    "num_steps = 10\n",
    "top_k = 5\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids\n",
    "df = {}\n",
    "for step in range(num_steps):\n",
    "    with torch.no_grad():\n",
    "        outputs = CLLM(input_ids=input_ids)\n",
    "        logits = outputs.logits\n",
    "        prob = torch.softmax(logits[:, -1, :], dim=-1,dtype=torch.float32)\n",
    "        sort_prob = torch.sort(prob, dim=-1, descending=True)\n",
    "        predicted_token_ids = torch.argsort(prob, dim=-1,descending=True)\n",
    "        dict = {}\n",
    "        for num in range(predicet_num):\n",
    "            sing_prob = sort_prob.values[0][num].item() * 100\n",
    "            dict[\"percentage\"+f\"位置{num}\"] = tokenizer.decode(predicted_token_ids[0][num])+ \"的概率\" + f\"{sing_prob:.4f}\" + \"%\"\n",
    "        dict[\"sentence\"+f\"第{step}次\"] = tokenizer.decode(input_ids[0])\n",
    "        dd = predicted_token_ids[0][0].unsqueeze(0)\n",
    "        input_ids = torch.cat([input_ids, dd.unsqueeze(0)], dim=-1) \n",
    "        df[f\"第{step}次\"] = dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ccf66764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>第0次</th>\n",
       "      <th>第1次</th>\n",
       "      <th>第2次</th>\n",
       "      <th>第3次</th>\n",
       "      <th>第4次</th>\n",
       "      <th>第5次</th>\n",
       "      <th>第6次</th>\n",
       "      <th>第7次</th>\n",
       "      <th>第8次</th>\n",
       "      <th>第9次</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>percentage位置0</th>\n",
       "      <td>\\n的概率17.3692%</td>\n",
       "      <td>\\n的概率99.4316%</td>\n",
       "      <td>I的概率7.2990%</td>\n",
       "      <td>'m的概率41.7102%</td>\n",
       "      <td>a的概率5.9283%</td>\n",
       "      <td>little的概率3.8726%</td>\n",
       "      <td>bit的概率13.4777%</td>\n",
       "      <td>of的概率6.2405%</td>\n",
       "      <td>a的概率81.7259%</td>\n",
       "      <td>nerd的概率2.2674%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage位置1</th>\n",
       "      <td>I的概率9.4105%</td>\n",
       "      <td>I的概率0.0567%</td>\n",
       "      <td>\"的概率3.1469%</td>\n",
       "      <td>am的概率12.6050%</td>\n",
       "      <td>not的概率4.2078%</td>\n",
       "      <td>bit的概率1.9160%</td>\n",
       "      <td>nervous的概率5.2475%</td>\n",
       "      <td>nervous的概率4.8432%</td>\n",
       "      <td>an的概率10.6300%</td>\n",
       "      <td>geek的概率1.2833%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage位置2</th>\n",
       "      <td>What的概率3.2945%</td>\n",
       "      <td>A的概率0.0290%</td>\n",
       "      <td>You的概率2.3875%</td>\n",
       "      <td>'ve的概率5.5294%</td>\n",
       "      <td>just的概率4.1196%</td>\n",
       "      <td>big的概率1.5891%</td>\n",
       "      <td>tired的概率4.4740%</td>\n",
       "      <td>older的概率4.7552%</td>\n",
       "      <td>both的概率1.7132%</td>\n",
       "      <td>fan的概率1.1876%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage位置3</th>\n",
       "      <td>How的概率3.2210%</td>\n",
       "      <td>The的概率0.0254%</td>\n",
       "      <td>The的概率1.9682%</td>\n",
       "      <td>was的概率4.2741%</td>\n",
       "      <td>fine的概率3.7082%</td>\n",
       "      <td>very的概率1.3934%</td>\n",
       "      <td>confused的概率3.7622%</td>\n",
       "      <td>tired的概率4.4886%</td>\n",
       "      <td>everything的概率0.5507%</td>\n",
       "      <td>mystery的概率1.0414%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage位置4</th>\n",
       "      <td>You的概率3.1656%</td>\n",
       "      <td>M的概率0.0099%</td>\n",
       "      <td>A的概率1.9201%</td>\n",
       "      <td>have的概率2.7005%</td>\n",
       "      <td>so的概率2.8267%</td>\n",
       "      <td>young的概率1.2249%</td>\n",
       "      <td>surprised的概率2.8281%</td>\n",
       "      <td>confused的概率3.0404%</td>\n",
       "      <td>the的概率0.4627%</td>\n",
       "      <td>mess的概率1.0347%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第0次</th>\n",
       "      <td>Hello, how are you?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第1次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第2次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第3次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第4次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI'm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第5次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI'm a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第6次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI'm a little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第7次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI'm a little bit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第8次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI'm a little bit of</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence第9次</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello, how are you?\\n\\nI'm a little bit of a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               第0次                    第1次  \\\n",
       "percentage位置0        \\n的概率17.3692%          \\n的概率99.4316%   \n",
       "percentage位置1          I的概率9.4105%            I的概率0.0567%   \n",
       "percentage位置2       What的概率3.2945%            A的概率0.0290%   \n",
       "percentage位置3        How的概率3.2210%          The的概率0.0254%   \n",
       "percentage位置4        You的概率3.1656%            M的概率0.0099%   \n",
       "sentence第0次    Hello, how are you?                    NaN   \n",
       "sentence第1次                    NaN  Hello, how are you?\\n   \n",
       "sentence第2次                    NaN                    NaN   \n",
       "sentence第3次                    NaN                    NaN   \n",
       "sentence第4次                    NaN                    NaN   \n",
       "sentence第5次                    NaN                    NaN   \n",
       "sentence第6次                    NaN                    NaN   \n",
       "sentence第7次                    NaN                    NaN   \n",
       "sentence第8次                    NaN                    NaN   \n",
       "sentence第9次                    NaN                    NaN   \n",
       "\n",
       "                                   第2次                       第3次  \\\n",
       "percentage位置0              I的概率7.2990%             'm的概率41.7102%   \n",
       "percentage位置1              \"的概率3.1469%             am的概率12.6050%   \n",
       "percentage位置2            You的概率2.3875%             've的概率5.5294%   \n",
       "percentage位置3            The的概率1.9682%             was的概率4.2741%   \n",
       "percentage位置4              A的概率1.9201%            have的概率2.7005%   \n",
       "sentence第0次                        NaN                       NaN   \n",
       "sentence第1次                        NaN                       NaN   \n",
       "sentence第2次    Hello, how are you?\\n\\n                       NaN   \n",
       "sentence第3次                        NaN  Hello, how are you?\\n\\nI   \n",
       "sentence第4次                        NaN                       NaN   \n",
       "sentence第5次                        NaN                       NaN   \n",
       "sentence第6次                        NaN                       NaN   \n",
       "sentence第7次                        NaN                       NaN   \n",
       "sentence第8次                        NaN                       NaN   \n",
       "sentence第9次                        NaN                       NaN   \n",
       "\n",
       "                                      第4次                           第5次  \\\n",
       "percentage位置0                 a的概率5.9283%              little的概率3.8726%   \n",
       "percentage位置1               not的概率4.2078%                 bit的概率1.9160%   \n",
       "percentage位置2              just的概率4.1196%                 big的概率1.5891%   \n",
       "percentage位置3              fine的概率3.7082%                very的概率1.3934%   \n",
       "percentage位置4                so的概率2.8267%               young的概率1.2249%   \n",
       "sentence第0次                           NaN                           NaN   \n",
       "sentence第1次                           NaN                           NaN   \n",
       "sentence第2次                           NaN                           NaN   \n",
       "sentence第3次                           NaN                           NaN   \n",
       "sentence第4次    Hello, how are you?\\n\\nI'm                           NaN   \n",
       "sentence第5次                           NaN  Hello, how are you?\\n\\nI'm a   \n",
       "sentence第6次                           NaN                           NaN   \n",
       "sentence第7次                           NaN                           NaN   \n",
       "sentence第8次                           NaN                           NaN   \n",
       "sentence第9次                           NaN                           NaN   \n",
       "\n",
       "                                               第6次  \\\n",
       "percentage位置0                       bit的概率13.4777%   \n",
       "percentage位置1                    nervous的概率5.2475%   \n",
       "percentage位置2                      tired的概率4.4740%   \n",
       "percentage位置3                   confused的概率3.7622%   \n",
       "percentage位置4                  surprised的概率2.8281%   \n",
       "sentence第0次                                    NaN   \n",
       "sentence第1次                                    NaN   \n",
       "sentence第2次                                    NaN   \n",
       "sentence第3次                                    NaN   \n",
       "sentence第4次                                    NaN   \n",
       "sentence第5次                                    NaN   \n",
       "sentence第6次    Hello, how are you?\\n\\nI'm a little   \n",
       "sentence第7次                                    NaN   \n",
       "sentence第8次                                    NaN   \n",
       "sentence第9次                                    NaN   \n",
       "\n",
       "                                                   第7次  \\\n",
       "percentage位置0                             of的概率6.2405%   \n",
       "percentage位置1                        nervous的概率4.8432%   \n",
       "percentage位置2                          older的概率4.7552%   \n",
       "percentage位置3                          tired的概率4.4886%   \n",
       "percentage位置4                       confused的概率3.0404%   \n",
       "sentence第0次                                        NaN   \n",
       "sentence第1次                                        NaN   \n",
       "sentence第2次                                        NaN   \n",
       "sentence第3次                                        NaN   \n",
       "sentence第4次                                        NaN   \n",
       "sentence第5次                                        NaN   \n",
       "sentence第6次                                        NaN   \n",
       "sentence第7次    Hello, how are you?\\n\\nI'm a little bit   \n",
       "sentence第8次                                        NaN   \n",
       "sentence第9次                                        NaN   \n",
       "\n",
       "                                                      第8次  \\\n",
       "percentage位置0                                a的概率81.7259%   \n",
       "percentage位置1                               an的概率10.6300%   \n",
       "percentage位置2                              both的概率1.7132%   \n",
       "percentage位置3                        everything的概率0.5507%   \n",
       "percentage位置4                               the的概率0.4627%   \n",
       "sentence第0次                                           NaN   \n",
       "sentence第1次                                           NaN   \n",
       "sentence第2次                                           NaN   \n",
       "sentence第3次                                           NaN   \n",
       "sentence第4次                                           NaN   \n",
       "sentence第5次                                           NaN   \n",
       "sentence第6次                                           NaN   \n",
       "sentence第7次                                           NaN   \n",
       "sentence第8次    Hello, how are you?\\n\\nI'm a little bit of   \n",
       "sentence第9次                                           NaN   \n",
       "\n",
       "                                                        第9次  \n",
       "percentage位置0                                nerd的概率2.2674%  \n",
       "percentage位置1                                geek的概率1.2833%  \n",
       "percentage位置2                                 fan的概率1.1876%  \n",
       "percentage位置3                             mystery的概率1.0414%  \n",
       "percentage位置4                                mess的概率1.0347%  \n",
       "sentence第0次                                             NaN  \n",
       "sentence第1次                                             NaN  \n",
       "sentence第2次                                             NaN  \n",
       "sentence第3次                                             NaN  \n",
       "sentence第4次                                             NaN  \n",
       "sentence第5次                                             NaN  \n",
       "sentence第6次                                             NaN  \n",
       "sentence第7次                                             NaN  \n",
       "sentence第8次                                             NaN  \n",
       "sentence第9次    Hello, how are you?\\n\\nI'm a little bit of a  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "270dee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
